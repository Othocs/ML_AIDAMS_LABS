{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgou9hIHSWZH"
      },
      "source": [
        "<center><img src='https://drive.google.com/uc?export=view&id=1qJ8NqAZolTBQY7lN-deZ8xEsU3dlUiLz' width=200></center>\n",
        "<center><img src='https://upload.wikimedia.org/wikipedia/commons/a/a4/Logo-essec.jpg' width=200></center>\n",
        "\n",
        "\n",
        "<h6><center></center></h6>\n",
        "\n",
        "<h1>\n",
        "<hr style=\" border:none; height:3px;\">\n",
        "<center>Bachelor AIDAMS</center>\n",
        "<center>Getting started with the various tools</center>\n",
        "    <center> Lab 1 : Getting started with the various tools </center>\n",
        "<hr style=\" border:none; height:3px;\">\n",
        "</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5pyBhQ3SWZJ"
      },
      "source": [
        "\n",
        "The goal of this exercise sheet is to explore several of the tools we will be using in these labs:\n",
        "\n",
        "* [Pandas](https://pandas.pydata.org/): a Python library specialized in data analysis, widely used in data science, particularly for data manipulation. This library allows you to handle data using **DataFrames** (data tables), which can be very useful.\n",
        "* [Scikit-learn](http://scikit-learn.org/stable/): a Python library dedicated to data mining and machine learning.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK2zhHVuSWZK"
      },
      "source": [
        "\n",
        "\n",
        "## SCIKIT-LEARN\n",
        "\n",
        "Scikit-learn is a Python library dedicated to data mining and machine learning, developed by a team at INRIA (the Parietal team at INRIA Paris Saclay). The library’s development community is very active, which means it evolves frequently and rapidly. The main objects it handles are NumPy arrays. This library offers a wide range of features and is extremely useful when you want to implement a complete data analysis pipeline.\n",
        "\n",
        "\n",
        "\n",
        "### Installing the library\n",
        "\n",
        "Install the library: [http://scikit-learn.org/stable/install.html](https://scikit-learn.org/stable/index.html)\n",
        "\n",
        "```\n",
        "pip install -U scikit-learn\n",
        "```\n",
        "\n",
        "The online documentation is very comprehensive and will need to be consulted frequently: [http://scikit-learn.org/stable/documentation.html](http://scikit-learn.org/stable/documentation.html)\n",
        "The reference language (API) is available at the following address: [http://scikit-learn.org/stable/modules/classes.html](http://scikit-learn.org/stable/modules/classes.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install scikit-learn"
      ],
      "metadata": {
        "id": "rHIe_oPEUlZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxd7yOauSWZL"
      },
      "source": [
        "\n",
        "\n",
        "### First Steps: Loading and Exploring Datasets\n",
        "\n",
        "#### The IRIS Dataset\n",
        "\n",
        "The [IRIS Data Set](http://archive.ics.uci.edu/ml/datasets/Iris) is a classic dataset in data analysis. It was introduced in 1936 by R.A. Fisher as an example for discriminant analysis. It contains 150 samples of observed features from three different iris species: *Setosa*, *Versicolor*, and *Virginica*. Each sample consists of 4 attributes:\n",
        "\n",
        "* sepal length in cm\n",
        "* sepal width in cm\n",
        "* petal length in cm\n",
        "* petal width in cm\n",
        "* and a class (the species).\n",
        "\n",
        "This dataset is available in scikit-learn under the `datasets` package. Like any dataset, it consists of:\n",
        "\n",
        "* **.data** which stores the data in an n:m array, where *n* is the number of instances and *m* is the number of attributes.\n",
        "* **.target** which stores the class labels for each instance.\n",
        "* **.target_names** which provides the names of the classes.\n",
        "* **.feature_names** which provides the names of the attributes.\n",
        "* **.DESCR** which contains a full description of the dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua1d3lhzSWZM"
      },
      "source": [
        "Load the dataset by running the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdbwnJWESWZN"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "irisData=datasets.load_iris()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLj_e4NaSWZO"
      },
      "source": [
        "Display the data, outputs, attributes, and class names of this dataset, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SSYBbWISWZO"
      },
      "outputs": [],
      "source": [
        "# TO DO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCPBk7dZSWZO"
      },
      "source": [
        "A complete description of the dataset is available with the following command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Xdu3PaSWZP"
      },
      "outputs": [],
      "source": [
        "print(irisData.DESCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm44o0E-SWZQ"
      },
      "source": [
        "#### Data Vizualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_a-6N7TSWZR"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# This first instruction tells Jupyter to insert the graphs\n",
        "# into the notebook rather than into an external window.\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "# change of the style of the graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBGkjJgLSWZR"
      },
      "outputs": [],
      "source": [
        "from itertools import cycle\n",
        "import pylab as pl\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def plot_2D(data,x_index,y_index):\n",
        "  # this formatter will label the colorbar with the correct target names\n",
        "  formatter = plt.FuncFormatter(lambda i, *args: data.target_names[int(i)])\n",
        "  plt.figure(figsize=(5, 4))\n",
        "  plt.scatter(data.data[:, x_index], data.data[:, y_index], c=data.target)\n",
        "  plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
        "  plt.xlabel(data.feature_names[x_index])\n",
        "  plt.ylabel(data.feature_names[y_index])\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "# The indices of the features that we are plotting\n",
        "x_index = 0\n",
        "y_index = 1\n",
        "\n",
        "plot_2D(irisData,x_index,y_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FniD3qbESWZS"
      },
      "source": [
        "Display the distribution of data according to other attribute pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IF9djfvSWZS"
      },
      "outputs": [],
      "source": [
        "# TO DO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code also be used to have a complete overview of the dataset with the ['seaborn'](https://seaborn.pydata.org/) library. Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics."
      ],
      "metadata": {
        "id": "6-w3PYWfYt65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# We need to load the data as a dataFrame\n",
        "iris = load_iris(as_frame=True)\n",
        "print(iris.keys())\n",
        "\n",
        "# Rename classes using the iris target names\n",
        "iris.frame[\"target\"] = iris.target_names[iris.target]\n",
        "_ = sns.pairplot(iris.frame, hue=\"target\")"
      ],
      "metadata": {
        "id": "BMezV4GOZDNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yaR2jPCSWZS"
      },
      "source": [
        "Is there a 2D space in which the data from one class would be linearly separable from the data from the other two classes, i.e., separable by one of several straight lines? If so, illustrate and give an approximate equation for one of the straight lines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7DWtFgaSWZS"
      },
      "outputs": [],
      "source": [
        "# TO DO\n",
        "# You have to write a code that do that"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaP8wEhiSWZT"
      },
      "source": [
        "#### DIGITS Dataset\n",
        "\n",
        "Digit data is data dedicated to character recognition available on the [UCI](https://archive.ics.uci.edu/datasets) website. It includes 1,797 images with a resolution of $8 \\times 8$, each image representing a handwritten digit. Each character appears as an $8 \\times 8$ matrix of $16$ grayscale pixels and is identified by a label. This is the *image* space. The data is stored as a three-index array (the *data* space).\n",
        "\n",
        "\n",
        "**Explore the dataset.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alqNpXWhSWZT"
      },
      "outputs": [],
      "source": [
        "# TO DO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsFVZcVSSWZT"
      },
      "source": [
        "The following Python code will allow you to display examples of images to be discriminated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftN0XUCtSWZT"
      },
      "outputs": [],
      "source": [
        "images_and_labels = list(zip(digits.images,digits.target))\n",
        "for index, (image,label) in enumerate(images_and_labels[:10]):\n",
        "    plt.subplot(2,5,index+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r,interpolation='nearest')\n",
        "    plt.title('Training : %i' %label)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt85ami8SWZU"
      },
      "source": [
        "**Write a script that can count the number of examples in each class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FBFBn4JSWZU"
      },
      "outputs": [],
      "source": [
        "# TO DO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbuCmvCtSWZU"
      },
      "source": [
        "#### Other datasets\n",
        "Many other datasets are directly available in **scikit-learn**: *boston, diabetes, linnerud...* Most of this data is available via a specific loading function, but it can also be easily retrieved via a **fetch** process, particularly for retrieving data from the [openml](https://www.openml.org/) website, by following the documentation below: [Fetch OpenML datasets](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#downloading-datasets-from-the-openml-org-repository).\n",
        "\n",
        "\n",
        "Similarly, it is possible to process large amounts of data using the **pandas** library.\n",
        "\n",
        "\n",
        "See also this [documentation](https://scikit-learn.org/stable/datasets/loading_other_datasets.html#loading-from-external-datasets) for loading datasets from other sources.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEq1ceBBSWZV"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mice = fetch_openml(name='miceprotein', version=4)\n",
        "\n",
        "print(mice.DESCR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the time to navigate in the [OpenML](https://www.openml.org/) website, load some of the datasets and plot some useful visualization of interesting statistics of the datasets with the seaborn library."
      ],
      "metadata": {
        "id": "xwKev62Ldw8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO"
      ],
      "metadata": {
        "id": "gl-4b9cDhwKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPIIv7WYSWZV"
      },
      "source": [
        "\n",
        "# PANDAS\n",
        "\n",
        "This section is inspired by the excellent french tutorials by [Philippe Besse](https://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-tutor2-python-pandas.pdf).\n",
        "Many other tutorials are available online: [http://pandas.pydata.org/pandas-docs/stable/tutorials.html](http://pandas.pydata.org/pandas-docs/stable/tutorials.html)\n",
        "\n",
        "The **Pandas** library provides many powerful features that have contributed to its success and to Python’s widespread use for extracting, preparing, and analyzing data. In particular, it offers:\n",
        "\n",
        "* **Objects**: the **Series** and **DataFrame** classes, or data tables.\n",
        "* **Read / Write**: creation and export of data tables from text files (delimited, .csv, fixed-width, compressed), binary files (HDF5 with PyTables), HTML, XML, JSON, MongoDB, SQL, etc.\n",
        "* **Table management**: row and column selection, transformations, reorganization by factor levels, discretization of quantitative variables, removal or simple imputation of missing data, random shuffling and sampling, dummy variables, string handling, etc.\n",
        "* **Basic statistics**: univariate and bivariate statistics, frequency tables (number of categories, null values, missing values, etc.), associated plots, group-based statistics, basic outlier detection, etc.\n",
        "* **Table manipulation**: concatenations, merges, joins, sorting, and type and format management.\n",
        "\n",
        "## Installation\n",
        "\n",
        "```bash\n",
        "pip3 install pandas\n",
        "```\n",
        "\n",
        "## Series\n",
        "\n",
        "A [Series](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html) is a one-dimensional object similar to an array, a list, or a column in a table. Each value is associated with an index, which by default is an integer from $0$ to $N−1$ (where $N$ is the length of the Series).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "QBoSiSFPfHJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZPwNegFSWZW"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "from pandas import Series\n",
        "import numpy\n",
        "s = Series([42, 'Bonjour!', 3.14, -5, None, numpy.nan])\n",
        "s.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4QyhwSBSWZW"
      },
      "source": [
        "You can also specify the indexes during creation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l_h1SilSWZW"
      },
      "outputs": [],
      "source": [
        "s2 = Series([42, 'Bonjour!', 3.14, -5, None, numpy.nan],\n",
        "            index=['int', 'string', 'pi', 'neg', 'missing1', 'missing2'])\n",
        "s2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1firgW2kSWZX"
      },
      "source": [
        "You can also build the Series from a dictionary if you provide an index with a dictionary; indexes that are not keys in the dictionary will be missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOdAGUIgSWZX"
      },
      "outputs": [],
      "source": [
        "city2cp_dict = {'Paris14': 75014, 'Paris18': 75018, 'Malakoff': 92240, 'Nice': 6300}\n",
        "cities = Series(city2cp_dict)\n",
        "cities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUZ97IPESWZX"
      },
      "source": [
        "## DataFrame\n",
        "\n",
        "A DataFrame is an object found in most data processing software. It is a matrix, each column is a **Series** and is of the same type (number, date, text), it can contain missing values (nan). Each column can be considered as the variables in a table.\n",
        "\n",
        "A DataFrame represents a data table, i.e., an ordered collection of columns. These columns/rows can be of different types (numeric, string, boolean). This is very similar to DataFrames in the R language (in appearance...), with more symmetrical processing of rows and columns. It is a two-dimensional array\n",
        "with row and column indexes, but it can also be seen as a list of **Series** sharing the same index. The column index (variable names) is an object of type dict (dictionary)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx89_8wPSWZY"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "l = [ { \"date\":\"2014-06-22\", \"prix\":220.0, \"devise\":\"euros\" },\n",
        "      { \"date\":\"2014-06-23\", \"prix\":221.0, \"devise\":\"euros\" },]\n",
        "df = pandas.DataFrame(l)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9UkpBptSWZY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\",\n",
        "\"Nevada\", \"Nevada\"],\n",
        "\"year\": [2000, 2001, 2002, 2001, 2002],\n",
        "\"pop\": [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
        "frame = pd.DataFrame(data)\n",
        "frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W2tpyppSWZY"
      },
      "outputs": [],
      "source": [
        "# Column order\n",
        "pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\"])\n",
        "frame2 = pd.DataFrame(data)\n",
        "frame2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDatqVwvSWZY"
      },
      "outputs": [],
      "source": [
        "# index of missing rows and values (NaN)\n",
        "frame2=pd.DataFrame(data, columns=[\"year\", \"state\",\n",
        "\"pop\", \"debt\"],\n",
        "index=[\"one\", \"two\", \"three\", \"four\", \"five\"])\n",
        "frame2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY4IjAw_SWZZ"
      },
      "outputs": [],
      "source": [
        "# column list\n",
        "frame.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5ch-v5xSWZZ"
      },
      "outputs": [],
      "source": [
        "# column value\n",
        "frame[\"state\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOiUJMlVSWZZ"
      },
      "outputs": [],
      "source": [
        "# column values\n",
        "frame.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pspyPM1KSWZk"
      },
      "outputs": [],
      "source": [
        "# \"imputation\"\n",
        "frame2[\"debt\"] = 16.5\n",
        "frame2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k-PgXJcSWZk"
      },
      "outputs": [],
      "source": [
        "# Create a variable\n",
        "frame2[\"eastern\"] = frame2.state == \"Ohio\"\n",
        "frame2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcIbdNvLSWZl"
      },
      "source": [
        "### Writing and reading dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DkwEqLvSWZl"
      },
      "source": [
        "This section briefly presents the functions that allow you to read/write a DataFrame in text/Excel formats. The encoding=utf-8 instruction is not mandatory but recommended when the data contains accents.\n",
        "\n",
        "#### Writing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQlza8VdSWZl"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "l = [ { \"date\":\"2014-06-22\", \"prix\":220.0, \"devise\":\"euros\" },\n",
        "      { \"date\":\"2014-06-23\", \"prix\":221.0, \"devise\":\"euros\" },]\n",
        "df = pandas.DataFrame(l)\n",
        "\n",
        "# writing in text format\n",
        "df.to_csv(\"exemple.txt\",sep=\"\\t\",encoding=\"utf-8\", index=False)\n",
        "\n",
        "# we look at what has been recorded\n",
        "with open(\"exemple.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "print(text)\n",
        "\n",
        "# we save in Excel format\n",
        "df.to_excel(\"exemple.xlsx\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1NEw51DSWZm"
      },
      "source": [
        "#### Reading\n",
        "\n",
        "We will work with the data: [heart.txt](/content/sample_data/heart.txt) (source: R. Rakotomalala).\n",
        "You have first to upload this file in your Colab space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUgZ8z4RSWZm"
      },
      "outputs": [],
      "source": [
        "#loading the file\n",
        "#df is the name of the data frame object created\n",
        "#sep specifies the column separator character\n",
        "#header = 0: row number 0 = field names\n",
        "#optionally, decimal can be used to indicate the decimal point\n",
        "df = pandas.read_table(\"sample_data/heart.txt\",sep = '\\t',header = 0)\n",
        "\n",
        "\n",
        "print(type(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oirmX_hKSWZm"
      },
      "outputs": [],
      "source": [
        "#display the first lines of the dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48CpxN7PSWZn"
      },
      "outputs": [],
      "source": [
        "#dimensions: number of rows, number of columns\n",
        "#the header row is not counted\n",
        "#in the number of rows\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjddfgjRSWZn"
      },
      "outputs": [],
      "source": [
        "#column enumeration\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHDSVbcESWZn"
      },
      "outputs": [],
      "source": [
        "#column types\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBf_RwPCSWZo"
      },
      "outputs": [],
      "source": [
        "#data description\n",
        "print(df.describe(include='all'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hss9WFQSWZo"
      },
      "source": [
        "#### Variable Manipulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci_XdfEUSWZo"
      },
      "outputs": [],
      "source": [
        "#access to a column\n",
        "print(df['sucre'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX3uksC0SWZp"
      },
      "outputs": [],
      "source": [
        "# other approach\n",
        "print(df.sucre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-nf360qSWZp"
      },
      "outputs": [],
      "source": [
        "#access a set of columns\n",
        "print(df[['sexe','sucre']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9k6SX_USWZp"
      },
      "outputs": [],
      "source": [
        "#a column is a vector (Series in Pandas terminology)\n",
        "#displaying the first values\n",
        "print(df['age'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9YqVlC9SWZq"
      },
      "outputs": [],
      "source": [
        "#display of latest values\n",
        "print(df['age'].tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCc0MJUxSWZq"
      },
      "source": [
        "#### Some statistics\n",
        "\n",
        "See [here](http://pandas.pydata.org/pandas-docs/stable/basics.html#summarizing-data-describe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtzANbGpSWZq"
      },
      "outputs": [],
      "source": [
        "print(df['age'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqspjaleSWZq"
      },
      "outputs": [],
      "source": [
        "#computing the mean\n",
        "print(df['age'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCBkTlUsSWZr"
      },
      "outputs": [],
      "source": [
        "#value count\n",
        "print(df['typedouleur'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2hVn1F4SWZr"
      },
      "outputs": [],
      "source": [
        "#sort the values of a variable in ascending order\n",
        "print(df['age'].sort_values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4ctQtj8SWZr"
      },
      "outputs": [],
      "source": [
        "#we can also obtain the indices of the sorted values\n",
        "print(df['age'].argsort())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzcJO7WvSWZs"
      },
      "outputs": [],
      "source": [
        "# Apply a functin\n",
        "import numpy\n",
        "#fonction call back\n",
        "def operation(x):\n",
        "    return(x.mean())\n",
        "#call the function on all columns of the DataFrame\n",
        "#axis = 0 ==> each column will be passed to the operation() function\n",
        "#the select_dtypes() selection allows you to exclude non-numeric variables\n",
        "\n",
        "resultat = df.select_dtypes(exclude=['object']).apply(operation,axis=0)\n",
        "print(resultat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R-Aus1SSWZs"
      },
      "source": [
        "####Indexed access to DataFrame data\n",
        "DataFrame values can be accessed via indexes or index ranges. The structure then behaves like a matrix.\n",
        "The top-left cell has coordinates (0,0).\n",
        "There are different ways to do this, but using `$.iloc[,]` is one of the simplest solutions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiPehuWJSWZs"
      },
      "outputs": [],
      "source": [
        "#value in  (0,0)\n",
        "print(df.iloc[0,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCqC3NNzSWZt"
      },
      "outputs": [],
      "source": [
        "#5 first values of all columns\n",
        "#rows => 0:5 (0 to 5 [not included])\n",
        "#columns = : (all columns)\n",
        "print(df.iloc[0:5,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsIBlKAmSWZt"
      },
      "outputs": [],
      "source": [
        "#list of individuals with type A pain\n",
        "print(df.loc[df['typedouleur']==\"A\",:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjIOid6LSWZt"
      },
      "outputs": [],
      "source": [
        "#list of individuals with type A pain and angine is true\n",
        "print(df.loc[(df['typedouleur']==\"A\") & (df['angine'] == \"oui\"),:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lgm2GB0hSWZu"
      },
      "outputs": [],
      "source": [
        "# Cross-tabulation of variables\n",
        "print(pandas.crosstab(df['sexe'],df['coeur']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKOe3EspSWZu"
      },
      "outputs": [],
      "source": [
        "#data disaggregation by gender\n",
        "g = df.groupby('sexe')\n",
        "#calculate the size of the sub-DataFrame associated with men\n",
        "print(g.get_group('masculin').shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbcorRgGSWZv"
      },
      "source": [
        "#### Exercise: Working with real data\n",
        "\n",
        "We will use open data provided by the National Assembly, specifically data on members of parliament in JSON format. It is available here: http://data.assemblee-nationale.fr/acteurs/deputes-en-exercice\n",
        "\n",
        "The first step will therefore be to:\n",
        " + Import the JSON file with Pandas\n",
        " + Understand the data structure\n",
        "\n",
        "Then, a series of simple analyses will be performed to answer the following questions:\n",
        " + Determine whether gender parity is respected\n",
        " + Represent the number of members of parliament by age group\n",
        " + Calculate the average age by gender\n",
        " + List professional categories and occupations, then represent this in a readable format by gender.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyeySFS8SWZv"
      },
      "outputs": [],
      "source": [
        "# TO DO"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}